{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ccabd95d76e4f5084e6447e5f0be172\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from openai.types import Embedding\n",
    "from dotenv import load_dotenv\n",
    "import pytest\n",
    "import os\n",
    "import logging\n",
    "import tiktoken \n",
    "from json import JSONDecodeError\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from cluestar import plot_text\n",
    "\n",
    "load_dotenv('.env.shared')\n",
    "load_dotenv('.env.secret')\n",
    "\n",
    "test = os.getenv('OPENAI_API_KEY')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ccabd95d76e4f5084e6447e5f0be172\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\qa_hackaton\\llm-hackathon\\code\\main_openai.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m openai_client \u001b[39m=\u001b[39m AzureOpenAI(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     api_key\u001b[39m=\u001b[39mtest,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     base_url\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mOPENAI_API_BASE\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     api_version\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mOPENAI_API_VERSION\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(openai_client\u001b[39m.\u001b[39mapi_key)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m completion \u001b[39m=\u001b[39m openai_client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mCompose a poem that explains the concept of recursion in programming.\u001b[39;49m\u001b[39m\"\u001b[39;49m}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/qa_hackaton/llm-hackathon/code/main_openai.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Dev\\qa_hackaton\\qavenv\\Lib\\site-packages\\openai\\_utils\\_utils.py:301\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 301\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Dev\\qa_hackaton\\qavenv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    553\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    599\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    600\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    601\u001b[0m             {\n\u001b[0;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[0;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    615\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    616\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[0;32m    617\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[0;32m    618\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    619\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    620\u001b[0m             },\n\u001b[0;32m    621\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[0;32m    622\u001b[0m         ),\n\u001b[0;32m    623\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    624\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    627\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    628\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Dev\\qa_hackaton\\qavenv\\Lib\\site-packages\\openai\\_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1050\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1051\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1059\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1060\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1061\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1062\u001b[0m     )\n\u001b[1;32m-> 1063\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Dev\\qa_hackaton\\qavenv\\Lib\\site-packages\\openai\\_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    834\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    840\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    841\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    843\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    844\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    845\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    846\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    847\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    848\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Dev\\qa_hackaton\\qavenv\\Lib\\site-packages\\openai\\_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    883\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    887\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
     ]
    }
   ],
   "source": [
    "openai_client = AzureOpenAI(\n",
    "    api_key=test,\n",
    "    base_url=os.getenv('OPENAI_API_BASE'),\n",
    "    api_version=os.getenv('OPENAI_API_VERSION')\n",
    ")\n",
    "print(openai_client.api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"The user will provide you with a paragraph of text and a metadata string.\n",
    "The data will follow this format:\n",
    "\n",
    "METADATA: \n",
    "PARAGRAPH:\n",
    "\n",
    "The paragraphs and metadata can be in different languages. They all come from the same domain of oil and gas exploration and production. \n",
    "\n",
    "You will create questions that can be answered from the text, alongside the answers to the questions.\n",
    "The metadata should always be explicitly written in the questions and explicitly written in the answers.\n",
    "You may also use exact sentences or shorten the sentences to phrases to generate examples.\n",
    "You may paraphrase the content in sentences or change them slightly but you must preserve both language and style of individual texts.\n",
    "If there are no examples to generate then create an empty list. \n",
    "Provide a confidence score between 0 and 1 for each of the question answer pairs where 1 is full confidence in the answer, and 0 is no confidence in the answer.\n",
    "\n",
    "You are to produce a JSON formatted output, with JSON output only in the following form:\n",
    "\n",
    "[{\"Q\": \"<Question 1a>\", \"A\": \"<Answer 1b>\", \"C\" : \"<Confidence 1c>\"}, \n",
    " {\"Q\": \"<Sentence 2a>\", \"A\": \"<Sentence 2b>\", \"C\" : \"<Confidence 2c>\"},\n",
    " ...,\n",
    " {\"Q\": \"<Sentence Na>\", \"A\": \"<Sentence Nb>\", \"C\" : \"<Confidence Nc>\"}]\n",
    "\n",
    "You are to determine yourself how many examples N you can come up with. Just make sure its always JSON formatted.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = lambda a, b: \"\"\"\n",
    "METADATA: \"\"\"+a+\"\"\" \n",
    "\n",
    "PARAGRAPH: \"\"\"+b \n",
    "\n",
    "metadata = \"15/5-1\"\n",
    "paragraph = 'IV PETROPHYSICS AND WELL PRODUCTIVITY IV. 1. Loq Interpretation Investigation of the logs in well 15/5-1 showed hydro- carbon sand in the interval 3558-3614 RKBx, corre- sponding to total thickness of 56 m. No hydrocarbon water contact was identified.  The sand section may be subdivided into four separate pay zones, each zone being separated by thin impermeable layers. Pay zone Pay interval Thickness Avg. porosity Avg. SW m RKB 1 3558.6-3590.9 15 11 2 3594.8-3597.9 12 25 4 3608.8-3613.7 12 22 Total 14 14 IV. Observations The upper zone is the main zone, equivalent to 83% of the oil column. The cut-off criteria used in the log evaluation were: x The CP1 log is used as depth reference. RKB elevation ,.2-5m Refer Ficrui-e IV.1 and 7eservoir Fvaluation Display Section 8.'\n",
    "prompt = user_prompt(metadata, paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'IV PETROPHYSICS AND WELL PRODUCTIVITY IV. 1. Loq Interpretation Investigation of the logs in well 15/5-1 showed hydro- carbon sand in the interval 3558-3614 RKBx, corre- sponding to total thickness of 56 m. No hydrocarbon water contact was identified.  The sand section may be subdivided into four separate pay zones, each zone being separated by thin impermeable layers. Pay zone Pay interval Thickness Avg. porosity Avg. SW m RKB 1 3558.6-3590.9 15 11 2 3594.8-3597.9 12 25 4 3608.8-3613.7 12 22 Total 14 14 IV. Observations The upper zone is the main zone, equivalent to 83% of the oil column. The cut-off criteria used in the log evaluation were: x The CP1 log is used as depth reference. RKB elevation ,.2-5m Refer Ficrui-e IV.1 and 7eservoir Fvaluation Display Section 8.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METADATA: 15/5-1 \n",
      "\n",
      "PARAGRAPH: IV PETROPHYSICS AND WELL PRODUCTIVITY IV. 1. Loq Interpretation Investigation of the logs in well 15/5-1 showed hydro- carbon sand in the interval 3558-3614 RKBx, corre- sponding to total thickness of 56 m. No hydrocarbon water contact was identified.  The sand section may be subdivided into four separate pay zones, each zone being separated by thin impermeable layers. Pay zone Pay interval Thickness Avg. porosity Avg. SW m RKB 1 3558.6-3590.9 15 11 2 3594.8-3597.9 12 25 4 3608.8-3613.7 12 22 Total 14 14 IV. Observations The upper zone is the main zone, equivalent to 83% of the oil column. The cut-off criteria used in the log evaluation were: x The CP1 log is used as depth reference. RKB elevation ,.2-5m Refer Ficrui-e IV.1 and 7eservoir Fvaluation Display Section 8.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shared environment variables, not secrets\n",
    "load_dotenv(\"../.env.shared\")\n",
    "load_dotenv(\"../.env.secret\")\n",
    "\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"OPENAI_API_BASE\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "completion = openai_client.chat.completions.create(model=os.environ[\"GPT432k_DEPLOYMENT\"], \n",
    "                                            messages=[{\"role\": \"system\", \n",
    "                                                       \"content\": system_prompt}, \n",
    "                                                       {\"role\": \"user\", \"content\": prompt}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Q\": \"What investigation was done in well 15/5-1?\", \"A\": \"Investigation of the logs in well 15/5-1 was done to show hydrocarbon sand in the interval 3558-3614 RKBx, corresponding to total thickness of 56 m. No hydrocarbon water contact was identified.\", \"C\" : \"1\"}, \n",
      " {\"Q\": \"Can the sand section in well 15/5-1 be divided?\", \"A\": \"Yes, the sand section may be subdivided into four separate pay zones, each zone being separated by thin impermeable layers in well 15/5-1.\", \"C\" : \"1\"} ,\n",
      " {\"Q\": \"Which is the main zone in the well 15/5-1?\", \"A\": \"The upper zone is the main zone, equivalent to 83% of the oil column in well 15/5-1.\", \"C\" : \"1\"},\n",
      " {\"Q\": \"What were the cut-off criteria used in the log evaluation of well 15/5-1?\", \"A\": \"The cut-off criteria used in the log evaluation of well 15/5-1 were: the CP1 log is used as depth reference and RKB elevation\", \"C\" : \"1\"}]\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "async def fetch(session, url, headers, data):\n",
    "    async with session.post(url, headers=headers, data=data) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def fetch_all(urls, headers, data, loop):\n",
    "    async with aiohttp.ClientSession(loop=loop) as session:\n",
    "        results = await asyncio.gather(*[fetch(session, url, headers, data) for url in urls], return_exceptions=True)\n",
    "        return results\n",
    "\n",
    "prompts = {\"prompt1\": \"Translate the following English text to French: '{text}'\", \"prompt2\": \"What is the weather like today?\"}\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'model': 'text-davinci-002',\n",
    "    'max_tokens': 60,\n",
    "}\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "urls = [f\"https://api.openai.com/v1/engines/davinci-codex/completions?prompt={prompt}\" for prompt in prompts.values()]\n",
    "responses = loop.run_until_complete(fetch_all(urls, headers, data, loop))\n",
    "\n",
    "for response in responses:\n",
    "    print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
