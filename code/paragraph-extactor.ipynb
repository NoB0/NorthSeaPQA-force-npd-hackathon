{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoC to extract paragraphs from lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "                                              0.0/12.1 MB ? eta -:--:--\n",
      "                                              0.1/12.1 MB 2.2 MB/s eta 0:00:06\n",
      "     -                                        0.5/12.1 MB 4.7 MB/s eta 0:00:03\n",
      "     --                                       0.8/12.1 MB 6.5 MB/s eta 0:00:02\n",
      "     ----                                     1.3/12.1 MB 7.6 MB/s eta 0:00:02\n",
      "     ------                                   2.0/12.1 MB 8.5 MB/s eta 0:00:02\n",
      "     --------                                 2.7/12.1 MB 9.4 MB/s eta 0:00:01\n",
      "     -----------                              3.4/12.1 MB 10.5 MB/s eta 0:00:01\n",
      "     --------------                           4.3/12.1 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------                          4.8/12.1 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------                       5.5/12.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------                    6.5/12.1 MB 12.5 MB/s eta 0:00:01\n",
      "     -------------------------                7.7/12.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ----------------------------             8.7/12.1 MB 14.3 MB/s eta 0:00:01\n",
      "     --------------------------------         9.8/12.1 MB 15.0 MB/s eta 0:00:01\n",
      "     ------------------------------------    11.4/12.1 MB 19.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.1/12.1 MB 19.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.1/12.1 MB 17.7 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "                                              0.0/122.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 122.3/122.3 kB 7.0 MB/s eta 0:00:00\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Downloading thinc-8.2.1-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------  1.5/1.5 MB 45.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 31.2 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "                                              0.0/479.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 479.7/479.7 kB 29.3 MB/s eta 0:00:00\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "                                              0.0/50.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.1/50.1 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "                                              0.0/57.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.0/57.0 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.30.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.10.11)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aleksander.jakobsen\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "                                              0.0/181.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 181.6/181.6 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "                                              0.0/6.6 MB ? eta -:--:--\n",
      "     ---------                                1.6/6.6 MB 25.0 MB/s eta 0:00:01\n",
      "     ------------------                       3.1/6.6 MB 33.0 MB/s eta 0:00:01\n",
      "     -------------------                      3.1/6.6 MB 28.5 MB/s eta 0:00:01\n",
      "     -----------------------------            4.9/6.6 MB 26.3 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.0/6.6 MB 27.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.6/6.6 MB 24.8 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aleksander.jakobsen\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.4)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "                                              0.0/45.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.0/45.0 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aleksander.jakobsen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, cloudpathlib, catalogue, blis, srsly, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 wasabi-1.1.2 weasel-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip stuff needed\n",
    "#%pip install openpyxl\n",
    "#%pip install nltk\n",
    "#%pip install spacy\n",
    "\n",
    "\n",
    "# Wellbore_nema \n",
    "# From release date extract year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aleksander.jakobsen\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "from spacy.cli import download\n",
    "download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'filename', 'page', 'content', 'possible_language', 'langdetect',\n",
       "       'content_could_be_natural_language', 'content_scrubbed_light',\n",
       "       'content_scrubbed_light_could_be_natural_language', 'WELLBORE NAME',\n",
       "       'WELL NAME', 'TYPE', 'INFO ITEM GROUP TYPE', 'INFO ITEM TYPE', 'TITLE',\n",
       "       'DESCRIPTION', 'CREATOR BA NAME', 'Short Dataset Id',\n",
       "       'Required Dataset', 'ROW CREATED DATE', 'PUBLIC', 'PUBLIC ACCESS',\n",
       "       'RELEASE DATE', 'FILE FORMAT', 'Size', 'DATA ORGANIZATION',\n",
       "       'DATA COLLECTION', 'CREATION PROCESS', 'DATA DOMAIN', 'REMARK',\n",
       "       'UNLOAD FILE PATH', 'UNLOAD FILE NAME', 'INFORMATION ITEM ID',\n",
       "       'Dataset Id', 'Last Modified', 'Update Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_file = \"../data/Norway - Diskos reports_5.xlsx\"\n",
    "df = pd.read_excel(path_to_file)\n",
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>content</th>\n",
       "      <th>possible_language</th>\n",
       "      <th>langdetect</th>\n",
       "      <th>content_could_be_natural_language</th>\n",
       "      <th>content_scrubbed_light</th>\n",
       "      <th>content_scrubbed_light_could_be_natural_language</th>\n",
       "      <th>WELLBORE NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>DATA COLLECTION</th>\n",
       "      <th>CREATION PROCESS</th>\n",
       "      <th>DATA DOMAIN</th>\n",
       "      <th>REMARK</th>\n",
       "      <th>UNLOAD FILE PATH</th>\n",
       "      <th>UNLOAD FILE NAME</th>\n",
       "      <th>INFORMATION ITEM ID</th>\n",
       "      <th>Dataset Id</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>Update Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>The Upper Dogger The Interval from 3627 to 368...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999977940633832]</td>\n",
       "      <td>True</td>\n",
       "      <td>The Upper Dogger The Interval from 3627 to 368...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>The above is underlain by 272 in thick sandsto...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999952423862815]</td>\n",
       "      <td>True</td>\n",
       "      <td>The above is underlain by 272 in thick sandsto...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>seen in the main Sleipner reservoir to date, -...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999966473882063]</td>\n",
       "      <td>True</td>\n",
       "      <td>seen in the main Sleipner reservoir to date, -...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.999994410115181]</td>\n",
       "      <td>False</td>\n",
       "      <td>TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>10</td>\n",
       "      <td>WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999961362929385]</td>\n",
       "      <td>True</td>\n",
       "      <td>WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252376</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>48</td>\n",
       "      <td>wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.5714274116776232, pt:0.2857141457066634,...</td>\n",
       "      <td>False</td>\n",
       "      <td>wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252377</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>49</td>\n",
       "      <td>IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...</td>\n",
       "      <td>en</td>\n",
       "      <td>[pt:0.8571396095099522, en:0.1428589548695462]</td>\n",
       "      <td>False</td>\n",
       "      <td>IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252378</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>50</td>\n",
       "      <td>Pressure (bar II Capillary Pressure Curve Comp...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.7142842662068939, pt:0.28571429811363974]</td>\n",
       "      <td>False</td>\n",
       "      <td>Pressure (bar II Capillary Pressure Curve Comp...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252379</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>51</td>\n",
       "      <td>Company STATQIL A/S Depth.. S.Q57...05...........</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.571427361092836, pt:0.42857077727642967]</td>\n",
       "      <td>False</td>\n",
       "      <td>Company STATQIL A/S Depth.. S.Q57...05Gr. Dens...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252380</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>52</td>\n",
       "      <td>13. I. L LI Company. 5TATKL A/$..................</td>\n",
       "      <td>en</td>\n",
       "      <td>[ro:0.8571375546638594, et:0.14286212081298896]</td>\n",
       "      <td>False</td>\n",
       "      <td>13. I. L LI Company. 5TATKL AWell /5/9-12Kair ...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252381 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             _id   \n",
       "0       997d83feeb81f8044b6447210ab739ad1e9a4f7f  \\\n",
       "1       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "2       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "3       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "4       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "...                                          ...   \n",
       "252376  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252377  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252378  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252379  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252380  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "\n",
       "                                                 filename  page   \n",
       "0                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     6  \\\n",
       "1                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     7   \n",
       "2                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     8   \n",
       "3                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     9   \n",
       "4                  15_6-5__WELL__15-06-05_PB-706-0719.pdf    10   \n",
       "...                                                   ...   ...   \n",
       "252376  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    48   \n",
       "252377  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    49   \n",
       "252378  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    50   \n",
       "252379  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    51   \n",
       "252380  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    52   \n",
       "\n",
       "                                                  content possible_language   \n",
       "0       The Upper Dogger The Interval from 3627 to 368...                en  \\\n",
       "1       The above is underlain by 272 in thick sandsto...                en   \n",
       "2       seen in the main Sleipner reservoir to date, -...                en   \n",
       "3       TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...                en   \n",
       "4       WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...                en   \n",
       "...                                                   ...               ...   \n",
       "252376  wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...                en   \n",
       "252377  IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...                en   \n",
       "252378  Pressure (bar II Capillary Pressure Curve Comp...                en   \n",
       "252379  Company STATQIL A/S Depth.. S.Q57...05...........                en   \n",
       "252380  13. I. L LI Company. 5TATKL A/$..................                en   \n",
       "\n",
       "                                               langdetect   \n",
       "0                                 [en:0.9999977940633832]  \\\n",
       "1                                 [en:0.9999952423862815]   \n",
       "2                                 [en:0.9999966473882063]   \n",
       "3                                  [en:0.999994410115181]   \n",
       "4                                 [en:0.9999961362929385]   \n",
       "...                                                   ...   \n",
       "252376  [en:0.5714274116776232, pt:0.2857141457066634,...   \n",
       "252377     [pt:0.8571396095099522, en:0.1428589548695462]   \n",
       "252378    [en:0.7142842662068939, pt:0.28571429811363974]   \n",
       "252379     [en:0.571427361092836, pt:0.42857077727642967]   \n",
       "252380    [ro:0.8571375546638594, et:0.14286212081298896]   \n",
       "\n",
       "        content_could_be_natural_language   \n",
       "0                                    True  \\\n",
       "1                                    True   \n",
       "2                                    True   \n",
       "3                                   False   \n",
       "4                                    True   \n",
       "...                                   ...   \n",
       "252376                              False   \n",
       "252377                              False   \n",
       "252378                              False   \n",
       "252379                              False   \n",
       "252380                              False   \n",
       "\n",
       "                                   content_scrubbed_light   \n",
       "0       The Upper Dogger The Interval from 3627 to 368...  \\\n",
       "1       The above is underlain by 272 in thick sandsto...   \n",
       "2       seen in the main Sleipner reservoir to date, -...   \n",
       "3       TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...   \n",
       "4       WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...   \n",
       "...                                                   ...   \n",
       "252376  wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...   \n",
       "252377  IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...   \n",
       "252378  Pressure (bar II Capillary Pressure Curve Comp...   \n",
       "252379  Company STATQIL A/S Depth.. S.Q57...05Gr. Dens...   \n",
       "252380  13. I. L LI Company. 5TATKL AWell /5/9-12Kair ...   \n",
       "\n",
       "        content_scrubbed_light_could_be_natural_language WELLBORE NAME  ...   \n",
       "0                                                   True        15/6-5  ...  \\\n",
       "1                                                   True        15/6-5  ...   \n",
       "2                                                   True        15/6-5  ...   \n",
       "3                                                  False        15/6-5  ...   \n",
       "4                                                   True        15/6-5  ...   \n",
       "...                                                  ...           ...  ...   \n",
       "252376                                             False       15/9-12  ...   \n",
       "252377                                             False       15/9-12  ...   \n",
       "252378                                             False       15/9-12  ...   \n",
       "252379                                             False       15/9-12  ...   \n",
       "252380                                             False       15/9-12  ...   \n",
       "\n",
       "                          DATA COLLECTION CREATION PROCESS DATA DOMAIN REMARK   \n",
       "0       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN  \\\n",
       "1       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "2       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "3       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "4       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "...                                   ...              ...         ...    ...   \n",
       "252376                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252377                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252378                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252379                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252380                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "\n",
       "                                  UNLOAD FILE PATH   \n",
       "0                                              NaN  \\\n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "...                                            ...   \n",
       "252376  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252377  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252378  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252379  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252380  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "\n",
       "                         UNLOAD FILE NAME INFORMATION ITEM ID   Dataset Id   \n",
       "0                                     NaN        3.182072e+08  14.05.01.00  \\\n",
       "1                                     NaN        3.182072e+08  14.05.01.00   \n",
       "2                                     NaN        3.182072e+08  14.05.01.00   \n",
       "3                                     NaN        3.182072e+08  14.05.01.00   \n",
       "4                                     NaN        3.182072e+08  14.05.01.00   \n",
       "...                                   ...                 ...          ...   \n",
       "252376  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252377  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252378  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252379  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252380  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "\n",
       "              Last Modified          Update Time  \n",
       "0       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "1       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "2       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "3       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "4       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "...                     ...                  ...  \n",
       "252376  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252377  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252378  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252379  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252380  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "\n",
       "[252381 rows x 36 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                                  object\n",
       "filename                                             object\n",
       "page                                                  int64\n",
       "content                                              object\n",
       "possible_language                                    object\n",
       "langdetect                                           object\n",
       "content_could_be_natural_language                      bool\n",
       "content_scrubbed_light                               object\n",
       "content_scrubbed_light_could_be_natural_language       bool\n",
       "WELLBORE NAME                                        object\n",
       "WELL NAME                                            object\n",
       "TYPE                                                 object\n",
       "INFO ITEM GROUP TYPE                                 object\n",
       "INFO ITEM TYPE                                       object\n",
       "TITLE                                                object\n",
       "DESCRIPTION                                          object\n",
       "CREATOR BA NAME                                      object\n",
       "Short Dataset Id                                    float64\n",
       "Required Dataset                                     object\n",
       "ROW CREATED DATE                                     object\n",
       "PUBLIC                                               object\n",
       "PUBLIC ACCESS                                       float64\n",
       "RELEASE DATE                                         object\n",
       "FILE FORMAT                                          object\n",
       "Size                                                float64\n",
       "DATA ORGANIZATION                                    object\n",
       "DATA COLLECTION                                      object\n",
       "CREATION PROCESS                                     object\n",
       "DATA DOMAIN                                          object\n",
       "REMARK                                               object\n",
       "UNLOAD FILE PATH                                     object\n",
       "UNLOAD FILE NAME                                     object\n",
       "INFORMATION ITEM ID                                 float64\n",
       "Dataset Id                                           object\n",
       "Last Modified                                        object\n",
       "Update Time                                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters:\n",
    "- \"INFO ITEM TYPE\" on \"DISCOVERY_EVALUATION_REPORT\"\n",
    "- \"content_could_be_natural_language\" = True\n",
    "- \"possible_language\" = \"en\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def concatonate_docs(df):\n",
    "        \"\"\"\n",
    "        Concatenates lines with same _id\n",
    "        params: df (DataFrame) - The DataFrame to process\n",
    "        returns: DataFrame with concatenated content by '_id'\n",
    "        \"\"\"\n",
    "        grouped_content = df.groupby('_id')['content'].apply(lambda x: ''.join(x.astype(str)))\n",
    "        result_df = grouped_content.reset_index(name='concatenated_content')\n",
    "        return result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Load spaCy's pre-trained English model. This step needs to be done only once,\n",
    "    # usually at the beginning of your script. The model is used for sentence tokenization.\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def filter_sentences(doc):\n",
    "        \"\"\"\n",
    "        Filters sentences to exclude document headings or enumerations.\n",
    "        \n",
    "        Params:\n",
    "        - doc (spaCy Doc): The spaCy Doc object containing the processed text.\n",
    "        \n",
    "        Returns:\n",
    "        - list: A list of sentences after excluding non-standard text patterns.\n",
    "        \"\"\"\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            # Matches sequences like \"1.\", \"1.1\", \"2.3.4\", etc., followed by a space and a capital letter\n",
    "            pattern = r\"\\d+(\\.\\d+)*\\s+[A-Z]\"\n",
    "            \n",
    "            # Check if the sentence does not start with the pattern (to filter out titles/headings)\n",
    "            if not re.match(pattern, sent.text):\n",
    "                sentences.append(sent.text.strip())  # Add the sentence to the list after stripping whitespace\n",
    "        return sentences\n",
    "\n",
    "    def define_passages(df, global_passage_id, passage_length):\n",
    "        \"\"\"\n",
    "        Splits documents into passages of complete sentences based on the specified passage length.\n",
    "        \n",
    "        Params:\n",
    "        - df (DataFrame): DataFrame with documents concatenated by '_id'.\n",
    "        - global_passage_id (int): An integer ID that uniquely identifies each passage.\n",
    "        - passage_length (int): The number of sentences in each passage.\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame: A new DataFrame with columns '_id', 'Passage_id', 'passage'.\n",
    "        - int: The updated global passage ID after processing the DataFrame.\n",
    "        \"\"\"\n",
    "        # Initialize a list to store passage data\n",
    "        passages_data = []\n",
    "\n",
    "        # Iterate through each row in the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            # Extract the document ID and concatenated content for the current row\n",
    "            doc_id = row['_id']\n",
    "            content = row['concatenated_content']\n",
    "            \n",
    "            # Process the content using spaCy to tokenize into sentences\n",
    "            doc = nlp(content)\n",
    "            \n",
    "            # Filter the sentences using the custom filter function\n",
    "            sentences = filter_sentences(doc)\n",
    "\n",
    "            # Group sentences into passages of the specified length\n",
    "            for i in range(0, len(sentences), passage_length):\n",
    "                # Join sentences to form a single passage text\n",
    "                passage = ' '.join(sentences[i:i+passage_length])\n",
    "                # Append the passage data to the list, including the unique passage ID\n",
    "                passages_data.append([doc_id, global_passage_id, passage])\n",
    "                # Increment the unique passage ID for the next passage\n",
    "                global_passage_id += 1\n",
    "\n",
    "        # Create a DataFrame from the passage data\n",
    "        passages_df = pd.DataFrame(passages_data, columns=['_id', 'Passage_id', 'passage'])\n",
    "        \n",
    "        # Return the DataFrame and the updated passage ID\n",
    "        return passages_df, global_passage_id\n",
    "\n",
    "\n",
    "    def base_df(df, passage_length):\n",
    "        \"\"\"\n",
    "        Process the DataFrame to return passages for all unique \"INFO ITEM TYPE\"\n",
    "\n",
    "        Params:\n",
    "        - df (DataFrame): Original DataFrame with different \"INFO ITEM TYPE\"s\n",
    "        - passage_length (int): Number of sentences that make up a passage\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame with \"INFO_ITEM_TYPE\", \"_id\", \"passage_id\", \"passage\"\n",
    "        \"\"\"\n",
    "        global_passage_id = 0\n",
    "        result_dfs = []  # List to hold intermediate DataFrames\n",
    "\n",
    "        # Get unique 'INFO ITEM TYPE'\n",
    "        info_item_types = df['INFO ITEM TYPE'].unique()\n",
    "\n",
    "        # Process each unique 'INFO ITEM TYPE'\n",
    "        for item_type in info_item_types:\n",
    "            # Subset the dataframe by 'INFO ITEM TYPE'\n",
    "            df_filtered = df[(df['INFO ITEM TYPE'] == item_type) &\n",
    "                            (df['content_could_be_natural_language'] == True) &\n",
    "                            (df['possible_language'] == 'en')]\\\n",
    "                            .reset_index(drop=True)\n",
    "            \n",
    "            concat_df = concatonate_docs(df_filtered)\n",
    "            passage_df, global_passage_id = define_passages(concat_df, global_passage_id, passage_length)\n",
    "            \n",
    "            # Add back the 'INFO ITEM TYPE' to be part of the result DataFrame\n",
    "            passage_df['INFO_ITEM_TYPE'] = item_type\n",
    "            result_dfs.append(passage_df)\n",
    "\n",
    "        # Concatenate all intermediate DataFrames\n",
    "        final_df = pd.concat(result_dfs).reset_index(drop=True)\n",
    "        \n",
    "        # Reorder columns to match the desired format\n",
    "        final_df = final_df[['INFO_ITEM_TYPE', '_id', 'Passage_id', 'passage']]\n",
    "\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_df = base_df(df[df['INFO ITEM TYPE'] == 'DISCOVERY_EVALUATION_REPORT'],passage_length=50) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_df.to_csv(\"passages_discovery_evaluation_report_50_sentences.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO_ITEM_TYPE</th>\n",
       "      <th>_id</th>\n",
       "      <th>Passage_id</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130481</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>59d3b7de417e13085ff1dbee2ce826ff2fe23165</td>\n",
       "      <td>130481</td>\n",
       "      <td>V FORMATION TESTER S.P.E. PL N5 Ended O.O.H.F....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130482</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>59d3b7de417e13085ff1dbee2ce826ff2fe23165</td>\n",
       "      <td>130482</td>\n",
       "      <td>14 mn Sampling chamber pressure reading at sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130483</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>59d3b7de417e13085ff1dbee2ce826ff2fe23165</td>\n",
       "      <td>130483</td>\n",
       "      <td>trip ? Reason for testing: Oil sample for PVT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130484</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>601b0da72cc6a2ec5015e66636cd167a4d3802fb</td>\n",
       "      <td>130484</td>\n",
       "      <td>LIST OF CONTENT Abstract I. Introduction 2. Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130485</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>601b0da72cc6a2ec5015e66636cd167a4d3802fb</td>\n",
       "      <td>130485</td>\n",
       "      <td>Appendix C: Core listing + core log. Appendix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130703</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>fc177ae8d5cf8ff470803445387f91e294ee0df7</td>\n",
       "      <td>130703</td>\n",
       "      <td>Analysts Name G. W. -COOPERasp lea alio Immo a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130704</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>fc177ae8d5cf8ff470803445387f91e294ee0df7</td>\n",
       "      <td>130704</td>\n",
       "      <td>- '  -  . -  . . - . Average Range Uncorr for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130705</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>fc177ae8d5cf8ff470803445387f91e294ee0df7</td>\n",
       "      <td>130705</td>\n",
       "      <td>-... - . . . iIMO II= OM NM MI 11111 MI Mill M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130706</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>fc177ae8d5cf8ff470803445387f91e294ee0df7</td>\n",
       "      <td>130706</td>\n",
       "      <td>2C 4814m 28.6.76 08.00-12.30 - - 10 litres mud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130707</th>\n",
       "      <td>DISCOVERY_EVALUATION_REPORT</td>\n",
       "      <td>fc177ae8d5cf8ff470803445387f91e294ee0df7</td>\n",
       "      <td>130707</td>\n",
       "      <td>FITs 1,1A,1B,2,2A,2B Rain with open port, shap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     INFO_ITEM_TYPE                                       _id   \n",
       "130481  DISCOVERY_EVALUATION_REPORT  59d3b7de417e13085ff1dbee2ce826ff2fe23165  \\\n",
       "130482  DISCOVERY_EVALUATION_REPORT  59d3b7de417e13085ff1dbee2ce826ff2fe23165   \n",
       "130483  DISCOVERY_EVALUATION_REPORT  59d3b7de417e13085ff1dbee2ce826ff2fe23165   \n",
       "130484  DISCOVERY_EVALUATION_REPORT  601b0da72cc6a2ec5015e66636cd167a4d3802fb   \n",
       "130485  DISCOVERY_EVALUATION_REPORT  601b0da72cc6a2ec5015e66636cd167a4d3802fb   \n",
       "...                             ...                                       ...   \n",
       "130703  DISCOVERY_EVALUATION_REPORT  fc177ae8d5cf8ff470803445387f91e294ee0df7   \n",
       "130704  DISCOVERY_EVALUATION_REPORT  fc177ae8d5cf8ff470803445387f91e294ee0df7   \n",
       "130705  DISCOVERY_EVALUATION_REPORT  fc177ae8d5cf8ff470803445387f91e294ee0df7   \n",
       "130706  DISCOVERY_EVALUATION_REPORT  fc177ae8d5cf8ff470803445387f91e294ee0df7   \n",
       "130707  DISCOVERY_EVALUATION_REPORT  fc177ae8d5cf8ff470803445387f91e294ee0df7   \n",
       "\n",
       "       Passage_id                                            passage  \n",
       "130481     130481  V FORMATION TESTER S.P.E. PL N5 Ended O.O.H.F....  \n",
       "130482     130482  14 mn Sampling chamber pressure reading at sur...  \n",
       "130483     130483  trip ? Reason for testing: Oil sample for PVT ...  \n",
       "130484     130484  LIST OF CONTENT Abstract I. Introduction 2. Ar...  \n",
       "130485     130485  Appendix C: Core listing + core log. Appendix ...  \n",
       "...           ...                                                ...  \n",
       "130703     130703  Analysts Name G. W. -COOPERasp lea alio Immo a...  \n",
       "130704     130704  - '  -  . -  . . - . Average Range Uncorr for ...  \n",
       "130705     130705  -... - . . . iIMO II= OM NM MI 11111 MI Mill M...  \n",
       "130706     130706  2C 4814m 28.6.76 08.00-12.30 - - 10 litres mud...  \n",
       "130707     130707  FITs 1,1A,1B,2,2A,2B Rain with open port, shap...  \n",
       "\n",
       "[227 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `df` is the DataFrame obtained from the base_df function\n",
    "disc_eval_df  = desired_df[desired_df['INFO_ITEM_TYPE'] == 'DISCOVERY_EVALUATION_REPORT'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatonate_docs(df):\n",
    "    \"\"\"\n",
    "    Concatonates lines with same _id\n",
    "    params:\n",
    "    returns:\n",
    "    \"\"\"\n",
    "    grouped_content = df.groupby('_id')['content'].apply(lambda x: ''.join(x.astype(str)))\n",
    "    # Reset the index to turn the Series back into a DataFrame\n",
    "    result_df = grouped_content.reset_index(name='concatenated_content')\n",
    "    return result_df\n",
    "\n",
    "def define_passages(df, global_passage_id, passage_length):\n",
    "    \"\"\"\n",
    "    Splits a document into passages of sentences.\n",
    "    \n",
    "    Expects df on format \"_id\", \"concatenated_content\"\n",
    "    \n",
    "    Params:\n",
    "    - df: DataFrame with the documents concatenated by '_id'\n",
    "    - passage_size: The number of sentences in each passage (default is 10)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the columns \"_id\", \"concatenated_content\", \"Passage_id\", \"passage\"\n",
    "    \"\"\"\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "    # Prepare a list to store the passages data\n",
    "    passages_data = []\n",
    "\n",
    "\n",
    "    # Iterate through each document\n",
    "    for index, row in df.iterrows():\n",
    "        doc_id = row['_id']\n",
    "        content = row['concatenated_content']\n",
    "        \n",
    "        # Tokenize the document into sentences\n",
    "        sentences = tokenizer.tokenize(content)\n",
    "\n",
    "        # Split sentences into passages\n",
    "        for i in range(0, len(sentences), passage_size):\n",
    "            passage = ' '.join(sentences[i:i+passage_size])\n",
    "            passages_data.append([doc_id, global_passage_id, passage])\n",
    "            global_passage_id += 1\n",
    "\n",
    "    # Create a new DataFrame with the passages data\n",
    "    passages_df = pd.DataFrame(passages_data, columns=['_id', 'Passage_id', 'passage'])\n",
    "\n",
    "    return passages_df, global_passage_id\n",
    "\n",
    "\n",
    "def  base_df(df,passage_length):\n",
    "\n",
    "    #filter input df\n",
    "    df_filtered =  df[(df['INFO ITEM TYPE'] == 'DISCOVERY_EVALUATION_REPORT') & (df['content_could_be_natural_language'] == True) & (df['possible_language'] == 'en')].reset_index()\n",
    "    concat_df = concatonate_docs(df_filtered)\n",
    "    print(concat_df)\n",
    "    global_passage_id = 0\n",
    "    passage_df, global_passage_id = define_passages(concat_df,global_passage_id=global_passage_id,passage_length=passage_length)\n",
    "    return passage_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = concatonate_docs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = concat.loc[1,'concatenated_content']\n",
    "\n",
    "\n",
    "file_name = \"output.txt\"\n",
    "\n",
    "# Open the file in write mode ('w'). This will create the file if it does not exist,\n",
    "# or overwrite it if it does.\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    file.write(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def define_passages(df, global_passage_id, passage_length):\n",
    "#     \"\"\"\n",
    "#     Splits a document into passages of sentences.\n",
    "    \n",
    "#     Expects df on format \"_id\", \"concatenated_content\"\n",
    "    \n",
    "#     Params:\n",
    "#     - df (DataFrame): DataFrame with the documents concatenated by '_id'\n",
    "#     - global_passage_id (int): Starting passage ID for the entire data processing\n",
    "#     - passage_length (int): The number of sentences in each passage\n",
    "\n",
    "#     Returns:\n",
    "#     - DataFrame with the columns \"_id\", \"concatenated_content\", \"Passage_id\", \"passage\"\n",
    "#     - New global_passage_id after processing the given DataFrame\n",
    "#     \"\"\"\n",
    "#     # Initialize the tokenizer\n",
    "#     tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "#     passages_data = []\n",
    "\n",
    "#     # Iterate through each document\n",
    "#     for index, row in df.iterrows():\n",
    "#         doc_id = row['_id']\n",
    "#         content = row['concatenated_content']\n",
    "#         sentences = tokenizer.tokenize(content)\n",
    "        \n",
    "#         for i in range(0, len(sentences), passage_length):\n",
    "#             passage = ' '.join(sentences[i:i+passage_length])\n",
    "#             passages_data.append([doc_id, global_passage_id, passage])\n",
    "#             global_passage_id += 1\n",
    "\n",
    "#     passages_df = pd.DataFrame(passages_data, columns=['_id', 'Passage_id', 'passage'])\n",
    "#     return passages_df, global_passage_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest code with ALL columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatonate_docs(df):\n",
    "    \"\"\"\n",
    "    Concatenates lines with the same _id and preserves specific columns.\n",
    "\n",
    "    Params:\n",
    "    - df (DataFrame): The DataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame with _id, concatenated content, 'wellbore name', \n",
    "                 'CREATOR BA NAME', and 'year'.\n",
    "    \"\"\"\n",
    "    # Group by _id while concatenating 'content' and keeping the first instance of the other specified columns\n",
    "    grouped = df.groupby('_id').agg({\n",
    "        'content': lambda contents: ' '.join(contents.dropna().astype(str)),\n",
    "        'WELLBORE NAME': 'first',\n",
    "        'CREATOR BA NAME': 'first',\n",
    "        'year': 'first'  # assuming 'year' has already been precomputed before calling this function\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename the column to match the expected structure and return the DataFrame\n",
    "    grouped.rename(columns={'content': 'concatenated_content'}, inplace=True)\n",
    "    return grouped\n",
    "\n",
    "def filter_sentences(doc):\n",
    "    \"\"\"\n",
    "    Filters out sentence-like strings such as enumerations or headings which are not actual sentences.\n",
    "\n",
    "    Params:\n",
    "    - doc (spaCy Doc): A spaCy Doc object containing tokenized text.\n",
    "\n",
    "    Returns:\n",
    "    - List: A filtered list of sentence strings.\n",
    "    \"\"\"\n",
    "    # Prepare an empty list to store the filtered sentences\n",
    "    sentences = []\n",
    "\n",
    "    # Define a regex pattern to match headings or enumerations\n",
    "    pattern = r'\\d+(\\.\\d+)*\\s+[A-Z]'\n",
    "\n",
    "    # Check each sentence and add it to the list if it doesn't match the pattern\n",
    "    for sent in doc.sents:\n",
    "        if not re.match(pattern, sent.text):\n",
    "            sentences.append(sent.text.strip())\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def define_passages(df, global_passage_id, passage_length):\n",
    "    \"\"\"\n",
    "    Splits documents into passages of complete sentences based on the specified passage length.\n",
    "    \n",
    "    Params:\n",
    "    - df (DataFrame): DataFrame with documents concatenated by '_id'.\n",
    "    - global_passage_id (int): An integer ID that uniquely identifies each passage.\n",
    "    - passage_length (int): The number of sentences in each passage.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: A new DataFrame with columns '_id', 'Passage_id', 'passage'.\n",
    "    - int: The updated global passage ID after processing the DataFrame.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store passage data\n",
    "    passages_data = []\n",
    "\n",
    "    # Your logic here to tokenize and create passages, appending them to passages_data\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the document ID and concatenated content for the current row\n",
    "        doc_id = row['_id']\n",
    "        content = row['concatenated_content']\n",
    "        \n",
    "        # Process the content using spaCy to tokenize into sentences\n",
    "        doc = nlp(content)\n",
    "        \n",
    "        # Filter the sentences using the custom filter function\n",
    "        sentences = filter_sentences(doc)\n",
    "\n",
    "        # Group sentences into passages of the specified length\n",
    "        for i in range(0, len(sentences), passage_length):\n",
    "            # Join sentences to form a single passage text\n",
    "            passage = ' '.join(sentences[i:i+passage_length])\n",
    "            # Append the passage data to the list, including the unique passage ID\n",
    "            passages_data.append([doc_id, global_passage_id, passage, row['WELLBORE NAME'], row['CREATOR BA NAME'],row['year']])\n",
    "            # Increment the unique passage ID for the next passage\n",
    "            global_passage_id += 1\n",
    "\n",
    "\n",
    "\n",
    "    # After processing all rows and creating passage texts with a unique ID:\n",
    "    passages_df = pd.DataFrame(passages_data, columns=['_id', 'Passage_id', 'passage','WELLBORE NAME', 'CREATOR BA NAME', 'year'])\n",
    "\n",
    "    # Return the DataFrame of passages along with the updated global passage ID\n",
    "    return passages_df, global_passage_id\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Assuming spacy and nltk punkt tokenizer are already loaded\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Assuming the functions filter_sentences and define_passages remain unchanged\n",
    "\n",
    "def concatonate_docs(df):\n",
    "    \"\"\"\n",
    "    Concatenates 'content' for rows with the same '_id', while also retaining other specified columns.\n",
    "    Incorporates the 'wellbore name', 'CREATOR BA NAME', and 'year' columns into the final DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the document and metadata.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing '_id', the concatenated 'content', 'wellbore name', 'CREATOR BA NAME', and 'year'.\n",
    "    \"\"\"\n",
    "    # Group the DataFrame by '_id' and concatenate the content for each group\n",
    "    # Also, keep the first encountered non-null value for 'wellbore name', 'CREATOR BA NAME', and 'year'\n",
    "    grouped_content = df.groupby('_id').agg({\n",
    "        'content': lambda x: ''.join(x.dropna().astype(str)),\n",
    "        'WELLBORE NAME': 'first',  # Retain 'wellbore name'\n",
    "        'CREATOR BA NAME': 'first',  # Retain 'CREATOR BA NAME'\n",
    "        'year': 'first'  # Retain the 'year', extracted from 'RELEASE DATE' beforehand\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename 'content' column to 'concatenated_content'\n",
    "    grouped_content.rename(columns={'content': 'concatenated_content'}, inplace=True)\n",
    "\n",
    "    return grouped_content\n",
    "\n",
    "def base_df(df, passage_length):\n",
    "    \"\"\"\n",
    "    Processes the input DataFrame, filters it by 'INFO ITEM TYPE', and then creates passages \n",
    "    from the 'content' column. Also retains 'wellbore name', 'CREATOR BA NAME', and extracts \n",
    "    the year from 'RELEASE DATE'.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the original documents and metadata.\n",
    "    - passage_length: The desired number of sentences in each passage.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with '_id', 'Passage_id', 'passage', 'wellbore name', 'CREATOR BA NAME', 'year', \n",
    "      and 'INFO_ITEM_TYPE'.\n",
    "    \"\"\"\n",
    "    # Create a copy of the filtered DataFrame to avoid 'SettingWithCopyWarning'\n",
    "    # Extract the year from 'RELEASE DATE'\n",
    "    df = df.copy()\n",
    "    df['year'] = pd.to_datetime(df['RELEASE DATE']).dt.year\n",
    "\n",
    "    # Initialize the global passage ID\n",
    "    global_passage_id = 0\n",
    "\n",
    "    # Prepare a list to store the combined results from all unique 'INFO ITEM TYPE' entries\n",
    "    result_dfs = []\n",
    "\n",
    "    # Get the unique 'INFO ITEM TYPE' values\n",
    "    for item_type in df['INFO ITEM TYPE'].unique():\n",
    "        # Filter the DataFrame by 'INFO ITEM TYPE' and whether the content is natural language in English\n",
    "        df_filtered = df[(df['INFO ITEM TYPE'] == item_type) &\n",
    "                         (df['content_could_be_natural_language']) &\n",
    "                         (df['possible_language'] == 'en')]\n",
    "\n",
    "        # Concatenate the content for rows with the same '_id' and retain additional specified columns\n",
    "        concat_df = concatonate_docs(df_filtered)\n",
    "\n",
    "        # Split the concatenate content into passages\n",
    "        passage_df, global_passage_id = define_passages(concat_df, global_passage_id, passage_length)\n",
    "        print(f\"Passage_df shape: {passage_df.shape}\")\n",
    "\n",
    "        # Add 'INFO ITEM TYPE' back into the resulting DataFrame\n",
    "        passage_df['INFO_ITEM_TYPE'] = item_type\n",
    "\n",
    "        # Append the passages DataFrame to the lis\n",
    "        # t for concatenation later\n",
    "        result_dfs.append(passage_df)\n",
    "\n",
    "    # Concatenate all intermediate passage DataFrames into one\n",
    "    final_df = pd.concat(result_dfs, ignore_index=True)\n",
    "    print(final_df.columns)\n",
    "\n",
    "    # Return the final DataFrame with the specified columns\n",
    "    return final_df[['INFO_ITEM_TYPE', '_id', 'Passage_id', 'passage', 'WELLBORE NAME', 'CREATOR BA NAME', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage_df shape: (50, 6)\n",
      "Index(['_id', 'Passage_id', 'passage', 'WELLBORE NAME', 'CREATOR BA NAME',\n",
      "       'year', 'INFO_ITEM_TYPE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "desired_df = base_df(df[df['INFO ITEM TYPE'] == 'DISCOVERY_EVALUATION_REPORT'],passage_length=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>content</th>\n",
       "      <th>possible_language</th>\n",
       "      <th>langdetect</th>\n",
       "      <th>content_could_be_natural_language</th>\n",
       "      <th>content_scrubbed_light</th>\n",
       "      <th>content_scrubbed_light_could_be_natural_language</th>\n",
       "      <th>WELLBORE NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>DATA COLLECTION</th>\n",
       "      <th>CREATION PROCESS</th>\n",
       "      <th>DATA DOMAIN</th>\n",
       "      <th>REMARK</th>\n",
       "      <th>UNLOAD FILE PATH</th>\n",
       "      <th>UNLOAD FILE NAME</th>\n",
       "      <th>INFORMATION ITEM ID</th>\n",
       "      <th>Dataset Id</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>Update Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>The Upper Dogger The Interval from 3627 to 368...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999977940633832]</td>\n",
       "      <td>True</td>\n",
       "      <td>The Upper Dogger The Interval from 3627 to 368...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>The above is underlain by 272 in thick sandsto...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999952423862815]</td>\n",
       "      <td>True</td>\n",
       "      <td>The above is underlain by 272 in thick sandsto...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>seen in the main Sleipner reservoir to date, -...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999966473882063]</td>\n",
       "      <td>True</td>\n",
       "      <td>seen in the main Sleipner reservoir to date, -...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.999994410115181]</td>\n",
       "      <td>False</td>\n",
       "      <td>TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>997d83feeb81f8044b6447210ab739ad1e9a4f7f</td>\n",
       "      <td>15_6-5__WELL__15-06-05_PB-706-0719.pdf</td>\n",
       "      <td>10</td>\n",
       "      <td>WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.9999961362929385]</td>\n",
       "      <td>True</td>\n",
       "      <td>WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...</td>\n",
       "      <td>True</td>\n",
       "      <td>15/6-5</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS SCANNED COMPLETION REPORTS</td>\n",
       "      <td>INTERP</td>\n",
       "      <td>WL.CMPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182072e+08</td>\n",
       "      <td>14.05.01.00</td>\n",
       "      <td>2022-03-29 00:00:00</td>\n",
       "      <td>2023-08-28 12:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252376</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>48</td>\n",
       "      <td>wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.5714274116776232, pt:0.2857141457066634,...</td>\n",
       "      <td>False</td>\n",
       "      <td>wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252377</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>49</td>\n",
       "      <td>IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...</td>\n",
       "      <td>en</td>\n",
       "      <td>[pt:0.8571396095099522, en:0.1428589548695462]</td>\n",
       "      <td>False</td>\n",
       "      <td>IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252378</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>50</td>\n",
       "      <td>Pressure (bar II Capillary Pressure Curve Comp...</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.7142842662068939, pt:0.28571429811363974]</td>\n",
       "      <td>False</td>\n",
       "      <td>Pressure (bar II Capillary Pressure Curve Comp...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252379</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>51</td>\n",
       "      <td>Company STATQIL A/S Depth.. S.Q57...05...........</td>\n",
       "      <td>en</td>\n",
       "      <td>[en:0.571427361092836, pt:0.42857077727642967]</td>\n",
       "      <td>False</td>\n",
       "      <td>Company STATQIL A/S Depth.. S.Q57...05Gr. Dens...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252380</th>\n",
       "      <td>d8b5ec0eb354bbf9e4865565faa4a890dbabfb45</td>\n",
       "      <td>15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...</td>\n",
       "      <td>52</td>\n",
       "      <td>13. I. L LI Company. 5TATKL A/$..................</td>\n",
       "      <td>en</td>\n",
       "      <td>[ro:0.8571375546638594, et:0.14286212081298896]</td>\n",
       "      <td>False</td>\n",
       "      <td>13. I. L LI Company. 5TATKL AWell /5/9-12Kair ...</td>\n",
       "      <td>False</td>\n",
       "      <td>15/9-12</td>\n",
       "      <td>...</td>\n",
       "      <td>DISKOS LEGACY DATA</td>\n",
       "      <td>LAB</td>\n",
       "      <td>WL.RC.SCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30</td>\n",
       "      <td>CORE_SCAL_1982-10-30_REPORT_1.PDF</td>\n",
       "      <td>1.017913e+10</td>\n",
       "      <td>02.25.01.00</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>2023-07-12 07:25:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252381 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             _id   \n",
       "0       997d83feeb81f8044b6447210ab739ad1e9a4f7f  \\\n",
       "1       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "2       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "3       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "4       997d83feeb81f8044b6447210ab739ad1e9a4f7f   \n",
       "...                                          ...   \n",
       "252376  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252377  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252378  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252379  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "252380  d8b5ec0eb354bbf9e4865565faa4a890dbabfb45   \n",
       "\n",
       "                                                 filename  page   \n",
       "0                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     6  \\\n",
       "1                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     7   \n",
       "2                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     8   \n",
       "3                  15_6-5__WELL__15-06-05_PB-706-0719.pdf     9   \n",
       "4                  15_6-5__WELL__15-06-05_PB-706-0719.pdf    10   \n",
       "...                                                   ...   ...   \n",
       "252376  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    48   \n",
       "252377  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    49   \n",
       "252378  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    50   \n",
       "252379  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    51   \n",
       "252380  15_9-12__ROCK AND CORE__CORE_SCAL_1982-10-30_R...    52   \n",
       "\n",
       "                                                  content possible_language   \n",
       "0       The Upper Dogger The Interval from 3627 to 368...                en  \\\n",
       "1       The above is underlain by 272 in thick sandsto...                en   \n",
       "2       seen in the main Sleipner reservoir to date, -...                en   \n",
       "3       TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...                en   \n",
       "4       WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...                en   \n",
       "...                                                   ...               ...   \n",
       "252376  wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...                en   \n",
       "252377  IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...                en   \n",
       "252378  Pressure (bar II Capillary Pressure Curve Comp...                en   \n",
       "252379  Company STATQIL A/S Depth.. S.Q57...05...........                en   \n",
       "252380  13. I. L LI Company. 5TATKL A/$..................                en   \n",
       "\n",
       "                                               langdetect   \n",
       "0                                 [en:0.9999977940633832]  \\\n",
       "1                                 [en:0.9999952423862815]   \n",
       "2                                 [en:0.9999966473882063]   \n",
       "3                                  [en:0.999994410115181]   \n",
       "4                                 [en:0.9999961362929385]   \n",
       "...                                                   ...   \n",
       "252376  [en:0.5714274116776232, pt:0.2857141457066634,...   \n",
       "252377     [pt:0.8571396095099522, en:0.1428589548695462]   \n",
       "252378    [en:0.7142842662068939, pt:0.28571429811363974]   \n",
       "252379     [en:0.571427361092836, pt:0.42857077727642967]   \n",
       "252380    [ro:0.8571375546638594, et:0.14286212081298896]   \n",
       "\n",
       "        content_could_be_natural_language   \n",
       "0                                    True  \\\n",
       "1                                    True   \n",
       "2                                    True   \n",
       "3                                   False   \n",
       "4                                    True   \n",
       "...                                   ...   \n",
       "252376                              False   \n",
       "252377                              False   \n",
       "252378                              False   \n",
       "252379                              False   \n",
       "252380                              False   \n",
       "\n",
       "                                   content_scrubbed_light   \n",
       "0       The Upper Dogger The Interval from 3627 to 368...  \\\n",
       "1       The above is underlain by 272 in thick sandsto...   \n",
       "2       seen in the main Sleipner reservoir to date, -...   \n",
       "3       TABLE WIRELINE LOGGING SUMMARY Well 15/6-5 Log...   \n",
       "4       WELLSITE SAMPLE DESCRIPTION HOLE SIZE: GEOL: R...   \n",
       "...                                                   ...   \n",
       "252376  wycousawNmp,moom-Liwm e8-1301 (opds aJod luaoJ...   \n",
       "252377  IrVEN,114111NMPuelgeoW-liO'su af-EM11 (Boods a...   \n",
       "252378  Pressure (bar II Capillary Pressure Curve Comp...   \n",
       "252379  Company STATQIL A/S Depth.. S.Q57...05Gr. Dens...   \n",
       "252380  13. I. L LI Company. 5TATKL AWell /5/9-12Kair ...   \n",
       "\n",
       "        content_scrubbed_light_could_be_natural_language WELLBORE NAME  ...   \n",
       "0                                                   True        15/6-5  ...  \\\n",
       "1                                                   True        15/6-5  ...   \n",
       "2                                                   True        15/6-5  ...   \n",
       "3                                                  False        15/6-5  ...   \n",
       "4                                                   True        15/6-5  ...   \n",
       "...                                                  ...           ...  ...   \n",
       "252376                                             False       15/9-12  ...   \n",
       "252377                                             False       15/9-12  ...   \n",
       "252378                                             False       15/9-12  ...   \n",
       "252379                                             False       15/9-12  ...   \n",
       "252380                                             False       15/9-12  ...   \n",
       "\n",
       "                          DATA COLLECTION CREATION PROCESS DATA DOMAIN REMARK   \n",
       "0       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN  \\\n",
       "1       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "2       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "3       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "4       DISKOS SCANNED COMPLETION REPORTS           INTERP     WL.CMPL    NaN   \n",
       "...                                   ...              ...         ...    ...   \n",
       "252376                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252377                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252378                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252379                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "252380                 DISKOS LEGACY DATA              LAB  WL.RC.SCAL    NaN   \n",
       "\n",
       "                                  UNLOAD FILE PATH   \n",
       "0                                              NaN  \\\n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "...                                            ...   \n",
       "252376  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252377  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252378  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252379  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "252380  WELL_15_9-12/WB_309-L/CORE_DATA_1982-10-30   \n",
       "\n",
       "                         UNLOAD FILE NAME INFORMATION ITEM ID   Dataset Id   \n",
       "0                                     NaN        3.182072e+08  14.05.01.00  \\\n",
       "1                                     NaN        3.182072e+08  14.05.01.00   \n",
       "2                                     NaN        3.182072e+08  14.05.01.00   \n",
       "3                                     NaN        3.182072e+08  14.05.01.00   \n",
       "4                                     NaN        3.182072e+08  14.05.01.00   \n",
       "...                                   ...                 ...          ...   \n",
       "252376  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252377  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252378  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252379  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "252380  CORE_SCAL_1982-10-30_REPORT_1.PDF        1.017913e+10  02.25.01.00   \n",
       "\n",
       "              Last Modified          Update Time  \n",
       "0       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "1       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "2       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "3       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "4       2022-03-29 00:00:00  2023-08-28 12:22:54  \n",
       "...                     ...                  ...  \n",
       "252376  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252377  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252378  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252379  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "252380  2023-04-25 00:00:00  2023-07-12 07:25:22  \n",
       "\n",
       "[252381 rows x 36 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
